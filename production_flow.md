The **real production flow** (not mock mode) and explain exactly when each framework is used and how they interact.

## üèóÔ∏è Real Production Flow Architecture

### **Phase 1: System Initialization**

```python
# main.py - System startup
async def initialize():
    # 1. Load settings (production mode)
    settings = Settings()  # ENVIRONMENT=production

    # 2. Initialize Azure services
    blob_storage = BlobStorageService()  # Real Azure Blob Storage

    # 3. Initialize A2A Protocol
    a2a_protocol = A2AProtocol()  # Agent-to-Agent communication

    # 4. Initialize CrewAI Orchestrator
    orchestrator = CrewOrchestrator()  # Uses CrewAI + LangChain
```
### **Phase 2: Real Compliance Workflow Execution**

When you run: `python cli.py check-compliance --store-id STORE_0001`

#### **Step 1: Data Retrieval (Azure + A2A)**
```python
# CrewOrchestrator.run_compliance_workflow()
async def run_compliance_workflow(store_id, date):
    # A2A Protocol: Request data from external systems
    contract_data = await self.a2a_protocol.request_data(
        target_system="contract_management",
        request_type="get_store_contracts",
        store_id=store_id
    )
    
    # Azure Blob Storage: Download store images and planograms
    store_images = await self.blob_storage.download_store_images(store_id, date)
    planograms = await self.blob_storage.download_planograms(store_id)
```

#### **Step 2: CrewAI Agent Orchestration**
```python
# CrewAI Framework takes over
crew_result = self.crew.kickoff(inputs={
    "store_id": store_id,
    "contract_data": contract_data,
    "store_images": store_images,
    "planograms": planograms
})
```

### **Phase 3: Individual Agent Execution (CrewAI + LangChain)**

#### **Agent 1: Contract Analysis Specialist**
```python
# Uses: CrewAI + LangChain + OpenAI
class ContractAnalysisAgent:
    def __init__(self):
        # LangChain: LLM wrapper
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.1)
        
        # CrewAI: Agent definition
        self.agent = Agent(
            role="Contract Analysis Specialist",
            llm=self.llm,  # LangChain LLM
            tools=[self.contract_parser_tool]
        )
    
    async def analyze_contracts(self, contract_data):
        # LangChain: Document processing
        docs = self.text_splitter.split_documents(contract_data)
        
        # LangChain: Vector store for semantic search
        vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())
        
        # CrewAI: Task execution with LLM
        analysis = await self.agent.execute_task(
            "Extract compliance requirements from contracts"
        )
        return analysis
```

#### **Agent 2: Visual Compliance Inspector**
```python
# Uses: CrewAI + LangChain + Computer Vision
class VisualComplianceAgent:
    def __init__(self):
        # LangChain: Multi-modal LLM
        self.llm = ChatOpenAI(model="gpt-4-vision-preview")
        
        # CrewAI: Agent with vision capabilities
        self.agent = Agent(
            role="Visual Compliance Inspector",
            llm=self.llm,
            tools=[self.image_analysis_tool, self.planogram_comparison_tool]
        )
    
    async def analyze_store_images(self, images, planograms):
        # Computer Vision: Image preprocessing
        processed_images = await self.preprocess_images(images)
        
        # LangChain: Vision-language processing
        for image in processed_images:
            analysis = await self.llm.ainvoke([
                HumanMessage(content=[
                    {"type": "text", "text": "Analyze this store image for compliance"},
                    {"type": "image_url", "image_url": {"url": image.url}}
                ])
            ])
        
        return compliance_violations
```

#### **Agent 3: Planogram Compliance Analyst**
```python
# Uses: CrewAI + LangChain + Specialized Tools
class PlanogramAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4")
        
        # LangChain: Custom tools
        self.tools = [
            Tool(
                name="planogram_parser",
                description="Parse planogram XML/JSON data",
                func=self.parse_planogram
            ),
            Tool(
                name="shelf_analyzer",
                description="Analyze shelf compliance",
                func=self.analyze_shelf_compliance
            )
        ]
        
        # CrewAI: Agent with specialized tools
        self.agent = Agent(
            role="Planogram Compliance Analyst",
            llm=self.llm,
            tools=self.tools
        )
```

### **Phase 4: Inter-Agent Communication (A2A Protocol)**

```python
# A2A Protocol: Agents communicate with each other
class A2AProtocol:
    async def agent_to_agent_communication(self):
        # Contract Agent ‚Üí Visual Agent
        contract_requirements = await self.send_message(
            from_agent="contract_analyst",
            to_agent="visual_inspector",
            message_type="compliance_requirements",
            data=contract_analysis_result
        )
        
        # Visual Agent ‚Üí Planogram Agent
        visual_findings = await self.send_message(
            from_agent="visual_inspector",
            to_agent="planogram_analyst",
            message_type="visual_violations",
            data=image_analysis_result
        )
        
        # All Agents ‚Üí Scoring Agent
        combined_data = await self.aggregate_findings([
            contract_requirements,
            visual_findings,
            planogram_analysis
        ])
```

### **Phase 5: Advanced Reasoning (Potential LangGraph Integration)**

```python
# LangGraph: Complex workflow orchestration (future enhancement)
class ComplianceWorkflowGraph:
    def __init__(self):
        # LangGraph: State-based workflow
        self.workflow = StateGraph(ComplianceState)
        
        # Define workflow nodes
        self.workflow.add_node("contract_analysis", self.analyze_contracts)
        self.workflow.add_node("image_analysis", self.analyze_images)
        self.workflow.add_node("cross_validation", self.cross_validate)
        self.workflow.add_node("scoring", self.calculate_score)
        
        # Define workflow edges (conditional routing)
        self.workflow.add_conditional_edges(
            "contract_analysis",
            self.should_analyze_images,
            {
                "yes": "image_analysis",
                "no": "scoring"
            }
        )
```

### **Phase 6: MCP (Model Context Protocol) Usage**

```python
# MCP: Standardized context sharing between models
class MCPContextManager:
    async def share_context_between_agents(self):
        # MCP: Create shared context
        shared_context = MCPContext(
            store_id="STORE_0001",
            compliance_standards=contract_requirements,
            visual_evidence=image_analysis,
            historical_data=previous_audits
        )
        
        # MCP: Distribute context to all agents
        for agent in self.agents:
            await agent.update_context(shared_context)
        
        # MCP: Maintain context consistency
        await self.sync_context_across_agents()
```

### **Phase 7: AutoGen Integration (Multi-Agent Conversations)**

```python
# AutoGen: Complex multi-agent discussions
class AutoGenComplianceTeam:
    def __init__(self):
        # AutoGen: Create conversable agents
        self.contract_expert = ConversableAgent(
            name="ContractExpert",
            llm_config={"model": "gpt-4"},
            system_message="You are a contract compliance expert"
        )
        
        self.visual_expert = ConversableAgent(
            name="VisualExpert", 
            llm_config={"model": "gpt-4-vision"},
            system_message="You are a visual compliance inspector"
        )
        
        self.manager = ConversableAgent(
            name="ComplianceManager",
            llm_config={"model": "gpt-4"},
            system_message="You coordinate compliance analysis"
        )
    
    async def run_compliance_discussion(self):
        # AutoGen: Multi-agent conversation
        chat_result = await self.manager.initiate_chat(
            [self.contract_expert, self.visual_expert],
            message="Analyze compliance for STORE_0001",
            max_turns=10
        )
        
        return chat_result.summary
```

## üîÑ **Complete Real Flow Summary**

### **Framework Usage Timeline:**

1. **System Init**: Azure Services + A2A Protocol setup
2. **Data Retrieval**: A2A Protocol requests + Azure Blob downloads
3. **Agent Creation**: CrewAI + LangChain LLM initialization
4. **Document Processing**: LangChain text splitting + embeddings
5. **Image Analysis**: LangChain vision models + computer vision
6. **Agent Coordination**: CrewAI task orchestration
7. **Inter-Agent Communication**: A2A Protocol message passing
8. **Context Sharing**: MCP protocol for shared understanding
9. **Complex Reasoning**: LangGraph for conditional workflows
10. **Multi-Agent Discussions**: AutoGen for collaborative analysis
11. **Final Scoring**: Combined results from all frameworks

### **When Each Framework is Used:**

- **CrewAI**: Primary agent orchestration and task management
- **LangChain**: LLM wrappers, document processing, tool integration
- **LangGraph**: Complex conditional workflows and state management
- **AutoGen**: Multi-agent conversations and collaborative reasoning
- **A2A Protocol**: Inter-system and inter-agent communication
- **MCP**: Standardized context sharing between different models/agents

### **Real vs Mock Mode:**

- **Mock Mode**: Skips all AI calls, returns fake data instantly
- **Real Mode**: Full pipeline with actual API calls, image analysis, and AI reasoning

The beauty of this architecture is that each framework handles what it does best, creating a comprehensive compliance monitoring system that can scale across thousands of stores!





# üéØ **Phase Triggering Analysis**

### **Phase 3: Individual Agent Execution**

**WHO STARTS IT:** CrewAI's `crew.kickoff()` method
**WHEN:** After data retrieval is complete

# agents/orchestrator/crew_orchestrator.py
async def run_compliance_workflow(self, store_id, date):
    # Phase 1 & 2: Data retrieval completed

    # üöÄ THIS LINE TRIGGERS PHASE 3
    crew_result = self.crew.kickoff(inputs={
        "store_id": store_id,
        "contract_data": contract_data,
        "store_images": store_images,
        "planograms": planograms
    })

    # CrewAI internally does this:
    # 1. crew.kickoff() ‚Üí starts sequential task execution
    # 2. For each task in self.tasks:
    #    - Assigns task to designated agent
    #    - Agent.execute() is called
    #    - LLM processing happens here

**DETAILED BREAKDOWN:**
```python
# Inside CrewAI framework (simplified)
class Crew:
    def kickoff(self, inputs):
        for task in self.tasks:  # Sequential execution
            # üéØ THIS TRIGGERS INDIVIDUAL AGENT EXECUTION
            result = task.agent.execute(task, inputs)
            inputs.update(result)  # Pass results to next agent
        return final_result
```

### **Phase 4: Inter-Agent Communication (A2A Protocol)**

**WHO STARTS IT:** Each individual agent during their execution
**WHEN:** During Phase 3, when agents need to share information

```python
# Inside each agent's execution (Phase 3)
class ContractAnalysisAgent:
    async def execute_task(self, task, inputs):
        # Agent does its analysis
        contract_analysis = await self.analyze_contracts(inputs['contract_data'])
        
        # üöÄ AGENT TRIGGERS A2A COMMUNICATION
        await self.a2a_protocol.broadcast_findings(
            agent_id=self.agent_id,
            findings=contract_analysis,
            target_agents=["visual_inspector", "planogram_analyst"]
        )
        
        # Also listen for messages from other agents
        other_agent_data = await self.a2a_protocol.receive_messages(self.agent_id)
        
        return enhanced_analysis
```

**TRIGGERING SEQUENCE:**
```python
# Phase 3 execution triggers A2A
Agent 1 (Contract) executes ‚Üí sends findings via A2A ‚Üí continues
Agent 2 (Visual) executes ‚Üí receives A2A data ‚Üí sends own findings ‚Üí continues  
Agent 3 (Planogram) executes ‚Üí receives all A2A data ‚Üí sends findings ‚Üí continues
```

### **Phase 5: Advanced Reasoning (LangGraph Integration)**

**WHO STARTS IT:** CrewAI Orchestrator (as an alternative to simple sequential execution)
**WHEN:** Instead of `crew.kickoff()` - this would be a different execution path

```python
# agents/orchestrator/crew_orchestrator.py
async def run_compliance_workflow(self, store_id, date):
    # Data retrieval completed...
    
    # CHOICE POINT: Simple CrewAI vs Advanced LangGraph
    if self.settings.USE_ADVANCED_REASONING:
        # üöÄ THIS TRIGGERS PHASE 5 (Alternative to Phase 3)
        result = await self.langgraph_workflow.execute(inputs)
    else:
        # Standard CrewAI execution (Phase 3)
        result = self.crew.kickoff(inputs)
```

**LangGraph Execution:**
```python
class ComplianceWorkflowGraph:
    async def execute(self, inputs):
        # üéØ LANGGRAPH CONTROLS THE FLOW
        state = ComplianceState(inputs)
        
        # LangGraph decides the execution path
        while not state.is_complete:
            next_node = self.determine_next_node(state)
            # This could trigger agents in different orders
            state = await self.execute_node(next_node, state)
        
        return state.final_result
```

### **Phase 6: MCP (Model Context Protocol) Usage**

**WHO STARTS IT:** Each agent when it needs to share/access context
**WHEN:** Throughout Phase 3, 4, or 5 - whenever context sharing is needed

```python
# Inside any agent during execution
class VisualComplianceAgent:
    async def analyze_store_images(self, images):
        # üöÄ AGENT TRIGGERS MCP CONTEXT ACCESS
        shared_context = await self.mcp_manager.get_shared_context(
            context_type="compliance_standards",
            store_id=self.current_store_id
        )
        
        # Use shared context in analysis
        analysis = await self.llm.analyze_with_context(images, shared_context)
        
        # üöÄ AGENT UPDATES MCP CONTEXT
        await self.mcp_manager.update_context(
            context_type="visual_findings",
            data=analysis
        )
```

**MCP TRIGGERING PATTERN:**
```python
# MCP is triggered by agents throughout execution
Agent starts ‚Üí requests MCP context ‚Üí processes ‚Üí updates MCP context ‚Üí continues
```

### **Phase 7: AutoGen Integration (Multi-Agent Conversations)**

**WHO STARTS IT:** CrewAI Orchestrator when complex discussions are needed
**WHEN:** After initial agent execution, when consensus or detailed analysis is required

```python
# agents/orchestrator/crew_orchestrator.py
async def run_compliance_workflow(self, store_id, date):
    # Phase 3: Individual agents completed
    initial_results = self.crew.kickoff(inputs)
    
    # Check if complex discussion is needed
    if self.requires_agent_discussion(initial_results):
        # üöÄ THIS TRIGGERS PHASE 7
        refined_results = await self.autogen_team.discuss_findings(initial_results)
        return refined_results
    
    return initial_results

def requires_agent_discussion(self, results):
    # Trigger AutoGen if:
    return (
        results.has_conflicting_findings() or
        results.confidence_score < 0.8 or
        results.has_edge_cases()
    )
```

**AutoGen Execution:**
```python
class AutoGenComplianceTeam:
    async def discuss_findings(self, initial_results):
        # üéØ AUTOGEN MANAGES MULTI-AGENT CONVERSATION
        discussion = await self.manager.initiate_chat(
            participants=[self.contract_expert, self.visual_expert],
            message=f"Review and refine these findings: {initial_results}",
            termination_condition=self.consensus_reached
        )
        
        return discussion.final_consensus
```

## üîÑ **Complete Triggering Flow**

```python
# main.py or cli.py
result = await orchestrator.run_compliance_workflow(store_id, date)
                    ‚Üì
# CrewOrchestrator.run_compliance_workflow()
crew_result = self.crew.kickoff(inputs)  # üöÄ TRIGGERS PHASE 3
                    ‚Üì
# CrewAI Framework
for task in tasks:
    agent_result = task.agent.execute(task)  # Individual agent execution
                    ‚Üì
# Inside each agent execution
await self.a2a_protocol.send_message()  # üöÄ TRIGGERS PHASE 4
await self.mcp_manager.get_context()    # üöÄ TRIGGERS PHASE 6
                    ‚Üì
# Back in CrewOrchestrator
if needs_discussion:
    await self.autogen_team.discuss()   # üöÄ TRIGGERS PHASE 7
                    ‚Üì
# Alternative path (if configured)
await self.langgraph_workflow.execute() # üöÄ TRIGGERS PHASE 5
```

## üìã **Summary Table**

| Phase | Triggered By | When | Code Location |
|-------|-------------|------|---------------|
| **Phase 3** | `crew.kickoff()` | After data retrieval | `CrewOrchestrator.run_compliance_workflow()` |
| **Phase 4** | Individual agents | During agent execution | Inside each agent's `execute()` method |
| **Phase 5** | Orchestrator (alternative) | Instead of CrewAI kickoff | `CrewOrchestrator` (config-dependent) |
| **Phase 6** | Any agent needing context | Throughout execution | Inside agent methods when context needed |
| **Phase 7** | Orchestrator (conditional) | After initial results | `CrewOrchestrator` if discussion needed |

The key insight is that **Phase 3 is the main trigger** that starts the cascade, while other phases are either **embedded within Phase 3** (A2A, MCP) or **conditional alternatives/extensions** (LangGraph, AutoGen).